{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:ndp]",
      "language": "python",
      "name": "conda-env-ndp-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "Day_100_transfer_learning_HW.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChihHsiangChien/3rd-ML100Days/blob/master/homework/Day_100_transfer_learning_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMkNSpHe5Zr1",
        "colab_type": "text"
      },
      "source": [
        "## 作業\n",
        "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
        "\n",
        "\n",
        "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
        "\n",
        "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zprkwuCJ5Zr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.datasets import cifar10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUoyw__s6YjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d98ed7d5-a459-48c5-b815-86d9084b8d71"
      },
      "source": [
        "# 讀取資料集並作前處理\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efBzO9l-pVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#參數\n",
        "image_size = x_train.shape[1:3] #image size = (32,32)\n",
        "\n",
        "batch_size = 64      # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10     # 類別的數量，Cifar 10 共有 10 個類別\n",
        "epochs = 30          # 訓練整個資料集共 30個循環\n",
        "\n",
        "freeze_layers = 2    # 凍結網路層數"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwp7S7Pt6_vH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
        "augment_generator = ImageDataGenerator(\n",
        "    rotation_range=10, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1, \n",
        "    horizontal_flip=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h3OHBWx8ycN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJeVR2d88UqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "outputId": "a6540cbe-8cf4-4b9c-f572-f3d7ff342fc8"
      },
      "source": [
        "#建立ResNet50 model\n",
        "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
        "# 捨棄 ResNet50 頂層的 fully connected layers\n",
        "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
        "               input_shape=(image_size[0],image_size[1],3))\n",
        "x = net.output\n",
        "x = Flatten()(x)\n",
        "\n",
        "# 增加 DropOut layer\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
        "output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 8s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-44134131a1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 設定凍結與要進行訓練的網路層\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfreeze_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4uFkRCOBIF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ffe9a21b-a49f-4767-a00c-2c66c4748b13"
      },
      "source": [
        "\n",
        "# 設定凍結與要進行訓練的網路層\n",
        "model = Model(inputs=net.input, outputs=output_layer)\n",
        "for layer in model.layers[:freeze_layers]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[freeze_layers:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
        "model.compile(optimizer=Adam(lr=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 輸出整個網路結構\n",
        "print(model.summary())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 256)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 1, 1, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 10)           20490       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Q5xTfhAzJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32dfb001-f507-4ea2-f605-60cdfcd90ac7"
      },
      "source": [
        "\n",
        "# 訓練模型\n",
        "history = model.fit_generator(augment_generator.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "#\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "781/781 [==============================] - 110s 141ms/step - loss: 3.1318 - acc: 0.1616 - val_loss: 2.1168 - val_acc: 0.2817\n",
            "Epoch 2/30\n",
            "781/781 [==============================] - 90s 116ms/step - loss: 2.0783 - acc: 0.2854 - val_loss: 1.7331 - val_acc: 0.4326\n",
            "Epoch 3/30\n",
            "781/781 [==============================] - 89s 114ms/step - loss: 1.7319 - acc: 0.4107 - val_loss: 1.4299 - val_acc: 0.5325\n",
            "Epoch 4/30\n",
            "781/781 [==============================] - 88s 113ms/step - loss: 1.4651 - acc: 0.5035 - val_loss: 1.2419 - val_acc: 0.5859\n",
            "Epoch 5/30\n",
            "781/781 [==============================] - 88s 112ms/step - loss: 1.2885 - acc: 0.5591 - val_loss: 1.1047 - val_acc: 0.6302\n",
            "Epoch 6/30\n",
            "781/781 [==============================] - 87s 112ms/step - loss: 1.1567 - acc: 0.6059 - val_loss: 1.0015 - val_acc: 0.6654\n",
            "Epoch 7/30\n",
            "781/781 [==============================] - 88s 112ms/step - loss: 1.0707 - acc: 0.6380 - val_loss: 0.9582 - val_acc: 0.6852\n",
            "Epoch 8/30\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.9867 - acc: 0.6651 - val_loss: 0.9161 - val_acc: 0.7004\n",
            "Epoch 9/30\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.9278 - acc: 0.6848 - val_loss: 0.8497 - val_acc: 0.7157\n",
            "Epoch 10/30\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.8722 - acc: 0.7037 - val_loss: 0.7978 - val_acc: 0.7329\n",
            "Epoch 11/30\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.8292 - acc: 0.7167 - val_loss: 0.7769 - val_acc: 0.7423\n",
            "Epoch 12/30\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.7898 - acc: 0.7302 - val_loss: 0.7365 - val_acc: 0.7518\n",
            "Epoch 13/30\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.7612 - acc: 0.7401 - val_loss: 0.7243 - val_acc: 0.7568\n",
            "Epoch 14/30\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.7273 - acc: 0.7529 - val_loss: 0.7119 - val_acc: 0.7663\n",
            "Epoch 15/30\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.6934 - acc: 0.7618 - val_loss: 0.7328 - val_acc: 0.7694\n",
            "Epoch 16/30\n",
            "781/781 [==============================] - 85s 108ms/step - loss: 0.6759 - acc: 0.7673 - val_loss: 0.6999 - val_acc: 0.7792\n",
            "Epoch 17/30\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.6517 - acc: 0.7754 - val_loss: 0.6787 - val_acc: 0.7837\n",
            "Epoch 18/30\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.6270 - acc: 0.7845 - val_loss: 0.6440 - val_acc: 0.7866\n",
            "Epoch 19/30\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.6096 - acc: 0.7904 - val_loss: 0.6590 - val_acc: 0.7919\n",
            "Epoch 20/30\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.5925 - acc: 0.7962 - val_loss: 0.6532 - val_acc: 0.7937\n",
            "Epoch 21/30\n",
            "781/781 [==============================] - 83s 107ms/step - loss: 0.5750 - acc: 0.8020 - val_loss: 0.6601 - val_acc: 0.7962\n",
            "Epoch 22/30\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.5574 - acc: 0.8073 - val_loss: 0.6607 - val_acc: 0.7970\n",
            "Epoch 23/30\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.5383 - acc: 0.8151 - val_loss: 0.6272 - val_acc: 0.8016\n",
            "Epoch 24/30\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.5290 - acc: 0.8191 - val_loss: 0.6143 - val_acc: 0.8039\n",
            "Epoch 25/30\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.5121 - acc: 0.8212 - val_loss: 0.6301 - val_acc: 0.8032\n",
            "Epoch 26/30\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.5067 - acc: 0.8267 - val_loss: 0.5913 - val_acc: 0.8109\n",
            "Epoch 27/30\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.4867 - acc: 0.8349 - val_loss: 0.6082 - val_acc: 0.8104\n",
            "Epoch 28/30\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.4697 - acc: 0.8378 - val_loss: 0.6136 - val_acc: 0.8094\n",
            "Epoch 29/30\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.4594 - acc: 0.8424 - val_loss: 0.5859 - val_acc: 0.8109\n",
            "Epoch 30/30\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.4512 - acc: 0.8452 - val_loss: 0.6377 - val_acc: 0.8114\n",
            "Test loss: 0.6377064134597779\n",
            "Test accuracy: 0.8114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR5kf-prApe1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "6b7ddee7-b860-4c6a-d35a-4dd68be26b2e"
      },
      "source": [
        "#印出結果\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "plt.plot(model.history.history['acc'],label='acc')\n",
        "plt.plot(model.history.history['val_acc'], label='val_acc')\n",
        "plt.legend(loc=2)\n",
        "plt.show()\n",
        "plt.plot(model.history.history['loss'],label='loss')\n",
        "plt.plot(model.history.history['val_loss'], label='val_loss')\n",
        "plt.legend(loc=2)\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6377064134597779\n",
            "Test accuracy: 0.8114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg7PAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJhRENdKaXCiIa6UkqFEQ11pZQKI/8fPMavzOm+f5cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgHIyuNVBZB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}